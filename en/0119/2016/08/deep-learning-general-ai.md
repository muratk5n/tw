# Is Deep Learning, AI Overhyped?

François Chollet

[Chollet is an ML engineer at Google, also is the creator of the open
source deep-learning library Keras. Extremely useful tool, I've used
it along with many other practitioners in the field]

[Answering the question on Quora] In many respects, it is. For sure,
the recent successes of deep learning have been amazing: we went from
being really terrible at supervised learning on perceptual problems
(image classification, speech recognition) to being really good at
it. Deep learning has been transformative for many subfields of
machine learning. But here's the thing: lots of people, most of them
not directly involved with deep learning research, tend to extrapolate
too much from these recent successes. For instance, when we started
achieving below 4% top-5 error on the ImageNet classification task,
people started claiming that we had "solved" computer vision. We most
certainly haven't solved computer vision at this point; it's still a
tremendous challenge to generate accurate, precise descriptions of the
contents of a picture or a video, or to get meaningful answers to
basic visual queries (e.g. "get me a close-up of the handbag of the
second lady from the left"), things that humans take for granted. Our
successes, which while significant are still very limited in scope,
have fueled a narrative about AI being almost solved, a narrative
according to which machines can now "understand" images or
language. The reality is that we are very, very far away from that.

In the pitches of startups that are attempting to cash in on deep
learning, I see a lot of grossly unrealistic expectations. Some of
them are just naively over-optimistic, but some others are essentially
living in a fictional universe —I've seen at least 3 different
startups state that they would solve "general artificial intelligence"
in the next few years. Best of luck to them. Most of these companies
have no issue getting generously funded, but quite a few of them will
find it very difficult to get a decent exit. A lot of disappointment
will follow, especially among VCs and corporate decision makers, and
unless this is counter-balanced by a larger wave of successful
value-producing applications of deep learning, then we might witness a
new AI winter in the future.

Overall: deep learning has made us really good at turning large
datasets of perceptual inputs (images, sounds, videos) and simple
human-annotated targets (e.g. the list of objects present in a
picture) into models that can automatically map the inputs to the
targets. That's great, and it has a ton a transformative practical
applications. But it's still the only thing we can do really
well. Let's not mistake this fairly narrow success in supervised
learning for having "solved" machine perception, or machine
intelligence in general. The things about intelligence that we don't
understand still massively outnumber the things that we do understand,
and while we are standing one step closer to general AI than we did
ten years ago, it's only by a small increment.

[[-]](https://qr.ae/pGlN39)

[[Up]](../../2020/07/ai.html)
